# ðŸ§  Rakuten MLOps Project

## ðŸ” Objectif

Ce projet met en Å“uvre un pipeline MLOps complet pour la classification de produits Ã  partir de texte et d'images, incluant :

- APIs FastAPI pour le prÃ©traitement, la prÃ©diction et le rÃ©entraÃ®nement
- Monitoring via Prometheus & Grafana
- Tests unitaires automatisÃ©s avec Pytest
- Pipeline ZenML : Ã©valuation automatique, retrain conditionnel et alertes Slack

---

## ðŸš€ Lancement local

### 1. PrÃ©requis

- Docker & Docker Compose
- Python 3.12+
- Outils Python :
  ```bash
  pip install pip-tools pytest zenml[server] dvc dvc-s3
  ```
  ou
  ```bash
  pip install -r requirements-dev.txt
  ```
- RÃ©cupÃ©ration des donnÃ©es depuis DVC (voir les commandes d'authentification DVC sur [https://dagshub.com/BenoitLabreTak/projet_multimodal_Rakutten-GitHub](https://dagshub.com/BenoitLabreTak/projet_multimodal_Rakutten-GitHub)), puis lancer la commande:
```bash
dvc pull
```

### 2. Installation des dÃ©pendances

```bash
pip-compile requirements.in --output-file=requirements.txt
pip install -r requirements.txt
```

### 3. Configurer l'envoi de message sur Slack

#### CrÃ©er une url webhook Slack
- Aller sur [https://api.slack.com/apps/](https://api.slack.com/apps/)
- identifiez-vous
- CrÃ©er une nouvelle application vide (new app from scratch). 
- Dans le menu "Settings" sur la gauche, cliquez sur "Incoming Webhooks"
- Activez "Activate Incoming Webhooks" et rÃ©cupÃ©rez l'url indiquÃ©e

#### Configurez Alertmanager
- Recopier le fichier `monitoring/alertmanager/config-example.yml` vers `monitoring/alertmanager/config.yml` (Le fichier config.yml n'est pas suivi par Git car il contient des infos sensibles)
- complÃ©ter les informations nÃ©cessaires dans le fichier `config.yml`: 
  - `username`: le nom d'utilisateur Slack qui a Ã©tÃ© utilisÃ© lors de l'Ã©tape prÃ©cÃ©dente
  - `api_url`: l'url rÃ©cupÃ©rÃ©e lors de l'Ã©tape prÃ©cÃ©dente

#### Configurez le pipeline ZenML
- dÃ©finissez une variable d'environnement nommÃ©e `SLACK_WEBHOOK_URL` contenant l'url rÃ©cupÃ©rÃ©e.

### 4. Lancement des services

```bash
docker-compose up --build
```

- **API Swagger** : [http://localhost:8000/docs](http://localhost:8000/docs)
- **Prometheus** : [http://localhost:9090](http://localhost:9090)
- **Grafana** : [http://localhost:3000](http://localhost:3000)
  - Login : `admin` / Password : `admin` (par dÃ©faut)

---

## ðŸ“¡ Endpoints principaux

| MÃ©thode | Route                                 | Description                            |
|--------:|:--------------------------------------|:----------------------------------------|
| POST    | `/predict/text/manual`                | PrÃ©diction CamemBERT sur dÃ©signation + description |
| POST    | `/predict/image/manual`               | PrÃ©diction ResNet Ã  partir dâ€™une image  |
| POST    | `/train/text`                         | RÃ©entraÃ®nement du modÃ¨le texte          |
| POST    | `/train/image`                        | RÃ©entraÃ®nement du modÃ¨le image          |
| GET     | `/test/preprocess/text/manual`        | Lance le test unitaire associÃ©          |
| GET     | `/metrics`                            | Exposition Prometheus                   |

---

## ðŸ§ª Tests unitaires

```bash
pytest tests/
```
ou
```bash
docker compose run api pytest tests/
```

Lancement via API (Swagger ou cURL) :

```http
GET /test/preprocess/text/manual
```

Sortie JSON :
```json
{
  "exit_code": 0,
  "stdout": "...",
  "stderr": "",
  "success": true
}
```

---

## ðŸ“ˆ Monitoring

- Toutes les routes sont instrumentÃ©es avec `prometheus_fastapi_instrumentator`.
- **Prometheus** collecte les mÃ©triques.
- **Grafana** peut Ãªtre configurÃ© avec un dashboard personnalisÃ© (ex : latence, taux de succÃ¨s, requÃªtes/s).
  exemple de dashboard Ã  importer: https://grafana.com/grafana/dashboards/18739-fastapi-observability/
  exemple de dashboard Ã  importer pour les mÃ©triques conteneurs: https://grafana.com/grafana/dashboards/10619-docker-host-container-overview/ 

---

## ðŸ” Pipeline ZenML

### FonctionnalitÃ©s

- Ã‰valuation automatique (1% du dataset)
- RÃ©entraÃ®nement dÃ©clenchÃ© uniquement si le score F1 est insuffisant
- Notification Slack si un nouveau modÃ¨le est sauvegardÃ©

### ExÃ©cution
- s'assurer d'avoir dÃ©marrer le docker-compose avant

```bash
zenml init
# Pour envoyer des messages Slack, modifiez ci-dessous l'url "Incoming webhook" (voir Ã©tape 3)
export SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxxx/yyyyy
python pipelines/text_auto_eval_and_retrain_pipeline.py
python pipelines/image_auto_eval_and_retrain_pipeline.py
# consulter le dashboard:
zenml login --local --port 9000
```

### Refactorisation
POC RÃ©entrainement des modÃ¨les sans utilisation de l'API.
Avantages:
- n'impacte pas la disponibilitÃ© de l'API aux utilisateurs finaux
- n'expose pas sur Internet les processus de rÃ©entrainement
- utilise les artefacts pour conserver les Ã©tapes intermÃ©diaires:
  - permet de faire du drift monitoring en comparant plusieurs versions de modÃ¨les et donnÃ©es
  - permet de reprendre des rÃ©entrainements interrompus
- peut Ãªtre paramÃ©trÃ© pour exÃ©cuter les steps avec Docker, Airflow, Kubernetes pour plus de scalabilitÃ©, de paramÃ©trage de ressources cpu, et d'efficience
InconvÃ©nients:
- Il faut rÃ©implÃ©menter le processus de rÃ©entrainement qui l'est dÃ©jÃ  dans l'API
Voir [pipeline_refactor/README.md](pipeline_refactor/README.md)

---

## ðŸ“ Arborescence

```
rakuten_mlops/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ core/ : fichier de configuration de l'API
â”‚   â”œâ”€â”€ models/ : les modÃ¨les utilisÃ©s ou gÃ©nÃ©rÃ©s par l'application
â”‚   â””â”€â”€ services/
â”œâ”€â”€ tests/
â”œâ”€â”€ data/
â”œâ”€â”€ monitoring/ : fichiers de paramÃ©trages liÃ©s au monitoring
â”œâ”€â”€ pipelines/ : fichiers liÃ©s au pipeline de rÃ©entraineement
â”œâ”€â”€ pipelines_refactor/ : fichiers liÃ©s au pipeline de rÃ©entraineement dÃ©taillÃ©
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.in
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt : modules nÃ©cessaires pour exÃ©cuter le pipeline de rÃ©entrainement sur le poste
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ README.md
â””â”€â”€ run.py : lancement de l'application app
```

---

## âœ… Ã€ faire

- [ ] Ajouter dashboards Grafana par dÃ©faut
- [ ] IntÃ©gration continue (GitHub Actions)
- [ ] Tracking modÃ¨le complet via DagsHub ou MLflow
- [ ] Trigger automatique des tests en push/pull request

---

## ðŸ¤– Auteur

**Mehdi Malhas**  
> Machine Learning Engineer | MLOps  
> [LinkedIn](https://www.linkedin.com/in/mehdi-malhas)

**Fabrice Moreau**
> Machine Learning Engineer | MLOps  
> [LinkedIn](https://www.linkedin.com/in/fabrice-moreau)

**Benoit Labre-Takam**

**Nicolas Haddad**
